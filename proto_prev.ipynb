{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Use images to load inputs and targets </h2>\n",
    "Load file names and targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 28709 training images\n",
      "There are 7178 test images\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_files       \n",
    "from keras.utils import np_utils\n",
    "import numpy as np\n",
    "from glob import glob\n",
    "\n",
    "# load image filenames with corresponding targets\n",
    "def load_dataset(path):\n",
    "    data = load_files(path)\n",
    "    imgs = np.array(data['filenames'])\n",
    "    targets = np_utils.to_categorical(np.array(data['target']), 7)\n",
    "    return imgs, targets\n",
    "\n",
    "train_filenames, train_targets = load_dataset(\"../data/processed/train\")\n",
    "test_filenames, test_targets = load_dataset(\"../data/processed/test\")\n",
    "\n",
    "print(\"There are %d training images\" % len(train_filenames))\n",
    "print(\"There are %d test images\" % len(test_filenames))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "helpers to load image file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing import image\n",
    "from tqdm import tqdm\n",
    "def my_load_image(img_path):\n",
    "    img = image.load_img(img_path, target_size=(48,48))\n",
    "    arr = image.img_to_array(img)\n",
    "    return np.expand_dims(arr, axis=0)\n",
    "\n",
    "def my_load_images(paths):\n",
    "    imgs = [my_load_image(p) for p in tqdm(paths)]\n",
    "    return np.vstack(imgs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "load train image inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████| 28709/28709 [00:09<00:00, 3174.24it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████| 7178/7178 [00:02<00:00, 3246.37it/s]\n"
     ]
    }
   ],
   "source": [
    "train_inputs = my_load_images(train_filenames)\n",
    "train_inputs /= 255\n",
    "test_inputs = my_load_images(test_filenames)\n",
    "test_inputs /= 255"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Use csv to load inputs and targets </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "names=['emotion','pixels','usage']\n",
    "df=pd.read_csv('../data/processed/fer2013.csv',names=names, na_filter=False)\n",
    "train_df = df[df['usage']=='Training']\n",
    "validate_df = df[df['usage']=='PublicTest']\n",
    "test_df = df[df['usage']=='PrivateTest']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_from_df(df):\n",
    "    imgs = df['pixels']\n",
    "    t = df['emotion']\n",
    "    inputs = []\n",
    "    targets = []\n",
    "    for i in imgs.keys():\n",
    "        x = [int(p) for p in imgs[i].split()]\n",
    "        x = np.reshape(x,(48,48))\n",
    "        y = [0 for i in range(7)]\n",
    "        y[int(t[i])] = 1\n",
    "        inputs.append(x)\n",
    "        targets.append(y)\n",
    "    inputs = np.array(inputs,dtype=np.float32)\n",
    "    inputs = np.expand_dims(inputs,axis=3)\n",
    "    inputs /= 255\n",
    "    targets = np.array(targets, dtype=np.float32)\n",
    "    return inputs, targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "v_inputs, v_targets = load_from_df(validate_df)\n",
    "t_inputs, t_targets = load_from_df(test_df)\n",
    "tr_inputs, tr_targets = load_from_df(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[0.12941177]\n",
      "  [0.11764706]\n",
      "  [0.10980392]\n",
      "  ...\n",
      "  [0.15686275]\n",
      "  [0.19215687]\n",
      "  [0.26666668]]\n",
      "\n",
      " [[0.13333334]\n",
      "  [0.09803922]\n",
      "  [0.07843138]\n",
      "  ...\n",
      "  [0.13725491]\n",
      "  [0.18039216]\n",
      "  [0.25882354]]\n",
      "\n",
      " [[0.11764706]\n",
      "  [0.09019608]\n",
      "  [0.08235294]\n",
      "  ...\n",
      "  [0.10980392]\n",
      "  [0.1764706 ]\n",
      "  [0.25490198]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[0.44705883]\n",
      "  [0.21176471]\n",
      "  [0.1254902 ]\n",
      "  ...\n",
      "  [0.21176471]\n",
      "  [0.1764706 ]\n",
      "  [0.19607843]]\n",
      "\n",
      " [[0.32156864]\n",
      "  [0.13333334]\n",
      "  [0.11372549]\n",
      "  ...\n",
      "  [0.19607843]\n",
      "  [0.20392157]\n",
      "  [0.18431373]]\n",
      "\n",
      " [[0.5137255 ]\n",
      "  [0.26666668]\n",
      "  [0.10588235]\n",
      "  ...\n",
      "  [0.20784314]\n",
      "  [0.20784314]\n",
      "  [0.1764706 ]]]\n"
     ]
    }
   ],
   "source": [
    "print(np.expand_dims(train_inputs[:,:,:,0],axis=3)[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_21\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_97 (Conv2D)           (None, 48, 48, 32)        416       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_55 (MaxPooling (None, 24, 24, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_98 (Conv2D)           (None, 24, 24, 64)        8256      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_56 (MaxPooling (None, 12, 12, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_99 (Conv2D)           (None, 12, 12, 128)       32896     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_57 (MaxPooling (None, 6, 6, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_18 (Flatten)         (None, 4608)              0         \n",
      "_________________________________________________________________\n",
      "dense_52 (Dense)             (None, 256)               1179904   \n",
      "_________________________________________________________________\n",
      "dense_53 (Dense)             (None, 512)               131584    \n",
      "_________________________________________________________________\n",
      "dense_54 (Dense)             (None, 7)                 3591      \n",
      "=================================================================\n",
      "Total params: 1,356,647\n",
      "Trainable params: 1,356,647\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.utils import np_utils\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "\n",
    "proto = Sequential()\n",
    "\n",
    "proto.add(Conv2D(filters=32,kernel_size=2,padding='same',activation='relu',input_shape=(48,48,3)))\n",
    "proto.add(MaxPooling2D(pool_size=2))\n",
    "proto.add(Conv2D(filters=64,kernel_size=2,padding='same',activation='relu'))\n",
    "proto.add(MaxPooling2D(pool_size=2))\n",
    "proto.add(Conv2D(filters=128,kernel_size=2,padding='same',activation='relu'))\n",
    "proto.add(MaxPooling2D(pool_size=2))\n",
    "proto.add(Flatten())\n",
    "proto.add(Dense(256,activation='relu'))\n",
    "proto.add(Dense(512,activation='relu'))\n",
    "proto.add(Dense(7,activation='softmax'))\n",
    "\n",
    "proto.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "proto.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "448/449 [============================>.] - ETA: 0s - loss: 1.6478 - accuracy: 0.3439\n",
      "Epoch 00001: val_loss improved from inf to 1.47964, saving model to ..\\models\\mycnn_prototype.hdf5\n",
      "449/449 [==============================] - 41s 90ms/step - loss: 1.6476 - accuracy: 0.3439 - val_loss: 1.4796 - val_accuracy: 0.4333\n",
      "Epoch 2/10\n",
      "449/449 [==============================] - ETA: 0s - loss: 1.3877 - accuracy: 0.4657\n",
      "Epoch 00002: val_loss improved from 1.47964 to 1.33193, saving model to ..\\models\\mycnn_prototype.hdf5\n",
      "449/449 [==============================] - 42s 93ms/step - loss: 1.3877 - accuracy: 0.4657 - val_loss: 1.3319 - val_accuracy: 0.4781\n",
      "Epoch 3/10\n",
      "449/449 [==============================] - ETA: 0s - loss: 1.2603 - accuracy: 0.5192\n",
      "Epoch 00003: val_loss improved from 1.33193 to 1.25220, saving model to ..\\models\\mycnn_prototype.hdf5\n",
      "449/449 [==============================] - 43s 97ms/step - loss: 1.2603 - accuracy: 0.5192 - val_loss: 1.2522 - val_accuracy: 0.5188\n",
      "Epoch 4/10\n",
      "449/449 [==============================] - ETA: 0s - loss: 1.1652 - accuracy: 0.5585\n",
      "Epoch 00004: val_loss improved from 1.25220 to 1.21742, saving model to ..\\models\\mycnn_prototype.hdf5\n",
      "449/449 [==============================] - 42s 94ms/step - loss: 1.1652 - accuracy: 0.5585 - val_loss: 1.2174 - val_accuracy: 0.5309\n",
      "Epoch 5/10\n",
      "449/449 [==============================] - ETA: 0s - loss: 1.0756 - accuracy: 0.5963\n",
      "Epoch 00005: val_loss improved from 1.21742 to 1.20575, saving model to ..\\models\\mycnn_prototype.hdf5\n",
      "449/449 [==============================] - 42s 93ms/step - loss: 1.0756 - accuracy: 0.5963 - val_loss: 1.2057 - val_accuracy: 0.5437\n",
      "Epoch 6/10\n",
      "449/449 [==============================] - ETA: 0s - loss: 0.9798 - accuracy: 0.6311\n",
      "Epoch 00006: val_loss improved from 1.20575 to 1.19902, saving model to ..\\models\\mycnn_prototype.hdf5\n",
      "449/449 [==============================] - 44s 97ms/step - loss: 0.9798 - accuracy: 0.6311 - val_loss: 1.1990 - val_accuracy: 0.5559\n",
      "Epoch 7/10\n",
      "449/449 [==============================] - ETA: 0s - loss: 0.8840 - accuracy: 0.6693\n",
      "Epoch 00007: val_loss did not improve from 1.19902\n",
      "449/449 [==============================] - 42s 94ms/step - loss: 0.8840 - accuracy: 0.6693 - val_loss: 1.2288 - val_accuracy: 0.5607\n",
      "Epoch 8/10\n",
      "449/449 [==============================] - ETA: 0s - loss: 0.7798 - accuracy: 0.7116\n",
      "Epoch 00008: val_loss did not improve from 1.19902\n",
      "449/449 [==============================] - 41s 90ms/step - loss: 0.7798 - accuracy: 0.7116 - val_loss: 1.3029 - val_accuracy: 0.5475\n",
      "Epoch 9/10\n",
      "449/449 [==============================] - ETA: 0s - loss: 0.6778 - accuracy: 0.7513\n",
      "Epoch 00009: val_loss did not improve from 1.19902\n",
      "449/449 [==============================] - 41s 91ms/step - loss: 0.6778 - accuracy: 0.7513 - val_loss: 1.3683 - val_accuracy: 0.5546\n",
      "Epoch 10/10\n",
      "449/449 [==============================] - ETA: 0s - loss: 0.5646 - accuracy: 0.7925\n",
      "Epoch 00010: val_loss did not improve from 1.19902\n",
      "449/449 [==============================] - 42s 94ms/step - loss: 0.5646 - accuracy: 0.7925 - val_loss: 1.4930 - val_accuracy: 0.5614\n"
     ]
    }
   ],
   "source": [
    "from keras.callbacks import ModelCheckpoint\n",
    "\n",
    "epoch = 10\n",
    "\n",
    "checkpointer = ModelCheckpoint(filepath='..\\models\\mycnn_prototype.hdf5',verbose=1,save_best_only= True)\n",
    "\n",
    "hist = proto.fit(train_inputs, train_targets , \n",
    "          validation_data=(test_inputs , test_targets),\n",
    "          epochs= epoch, batch_size=64, callbacks=[checkpointer], verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x21dac8d6dd8>"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(hist.history['loss'], label='loss')\n",
    "plt.plot(hist.history['val_loss'], label='validation loss')\n",
    "plt.plot(hist.history['accuracy'], label='accuracy')\n",
    "plt.plot(hist.history['val_accuracy'], label='val_accuracy')\n",
    "plt.legend(loc=\"upper left\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_18\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_88 (Conv2D)           (None, 48, 48, 64)        128       \n",
      "_________________________________________________________________\n",
      "batch_normalization_14 (Batc (None, 48, 48, 64)        256       \n",
      "_________________________________________________________________\n",
      "dropout_13 (Dropout)         (None, 48, 48, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_89 (Conv2D)           (None, 48, 48, 128)       73856     \n",
      "_________________________________________________________________\n",
      "batch_normalization_15 (Batc (None, 48, 48, 128)       512       \n",
      "_________________________________________________________________\n",
      "dropout_14 (Dropout)         (None, 48, 48, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_90 (Conv2D)           (None, 48, 48, 256)       819456    \n",
      "_________________________________________________________________\n",
      "batch_normalization_16 (Batc (None, 48, 48, 256)       1024      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_48 (MaxPooling (None, 24, 24, 256)       0         \n",
      "_________________________________________________________________\n",
      "dropout_15 (Dropout)         (None, 24, 24, 256)       0         \n",
      "_________________________________________________________________\n",
      "flatten_15 (Flatten)         (None, 147456)            0         \n",
      "_________________________________________________________________\n",
      "dense_43 (Dense)             (None, 128)               18874496  \n",
      "_________________________________________________________________\n",
      "batch_normalization_17 (Batc (None, 128)               512       \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dropout_16 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_44 (Dense)             (None, 256)               33024     \n",
      "_________________________________________________________________\n",
      "batch_normalization_18 (Batc (None, 256)               1024      \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dropout_17 (Dropout)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_45 (Dense)             (None, 7)                 1799      \n",
      "=================================================================\n",
      "Total params: 19,806,087\n",
      "Trainable params: 19,804,423\n",
      "Non-trainable params: 1,664\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.utils import np_utils\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization, Activation\n",
    "from keras import layers\n",
    "\n",
    "model = Sequential()\n",
    "model.add(layers.Conv2D(64, (1, 1), padding='same', activation='relu', input_shape=(48, 48, 1)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(layers.Conv2D(128, (3, 3),padding='same', activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(layers.Conv2D(256, (5, 5),padding='same', activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(layers.MaxPooling2D((2, 2),padding=\"same\"))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "\n",
    "model.add(layers.Flatten())\n",
    "\n",
    "model.add(layers.Dense(128))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(layers.Dense(256))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(layers.Dense(7, activation='softmax'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.optimizers import Adam\n",
    "opt = Adam(lr=0.001)\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',optimizer=opt,metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      " 11/898 [..............................] - ETA: 30:00 - loss: 2.3014 - accuracy: 0.1818"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-135-4d675f572135>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      7\u001b[0m vgg_hist = model.fit(tr_inputs, tr_targets , \n\u001b[0;32m      8\u001b[0m           \u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mt_inputs\u001b[0m \u001b[1;33m,\u001b[0m \u001b[0mt_targets\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m           epochs=vgg_epoch, batch_size=32, callbacks=[vgg_checkpointer], verbose=1)\n\u001b[0m",
      "\u001b[1;32mc:\\users\\zhang\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    106\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    107\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 108\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    109\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    110\u001b[0m     \u001b[1;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\zhang\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1096\u001b[0m                 batch_size=batch_size):\n\u001b[0;32m   1097\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1098\u001b[1;33m               \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1099\u001b[0m               \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1100\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\zhang\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    778\u001b[0m       \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    779\u001b[0m         \u001b[0mcompiler\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"nonXla\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 780\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    781\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    782\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\zhang\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    805\u001b[0m       \u001b[1;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    806\u001b[0m       \u001b[1;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 807\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=not-callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    808\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    809\u001b[0m       \u001b[1;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\zhang\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2827\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2828\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2829\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2830\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2831\u001b[0m   \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\zhang\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[1;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1846\u001b[0m                            resource_variable_ops.BaseResourceVariable))],\n\u001b[0;32m   1847\u001b[0m         \u001b[0mcaptured_inputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1848\u001b[1;33m         cancellation_manager=cancellation_manager)\n\u001b[0m\u001b[0;32m   1849\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1850\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\zhang\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1922\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1923\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[1;32m-> 1924\u001b[1;33m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[0;32m   1925\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[0;32m   1926\u001b[0m         \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\zhang\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    548\u001b[0m               \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    549\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 550\u001b[1;33m               ctx=ctx)\n\u001b[0m\u001b[0;32m    551\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    552\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[1;32mc:\\users\\zhang\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[1;32m---> 60\u001b[1;33m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[0;32m     61\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from keras.callbacks import ModelCheckpoint\n",
    "\n",
    "vgg_epoch = 10\n",
    "\n",
    "vgg_checkpointer = ModelCheckpoint(filepath='..\\models\\vgg_prototype.hdf5',verbose=1,save_best_only= True)\n",
    "\n",
    "vgg_hist = model.fit(tr_inputs, tr_targets , \n",
    "          validation_data=(t_inputs , t_targets),\n",
    "          epochs=vgg_epoch, batch_size=32, callbacks=[vgg_checkpointer], verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_26\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten_23 (Flatten)         (None, 2304)              0         \n",
      "_________________________________________________________________\n",
      "dense_71 (Dense)             (None, 256)               590080    \n",
      "_________________________________________________________________\n",
      "dense_72 (Dense)             (None, 512)               131584    \n",
      "_________________________________________________________________\n",
      "dense_73 (Dense)             (None, 1024)              525312    \n",
      "_________________________________________________________________\n",
      "dense_74 (Dense)             (None, 7)                 7175      \n",
      "=================================================================\n",
      "Total params: 1,254,151\n",
      "Trainable params: 1,254,151\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.utils import np_utils\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization, Activation\n",
    "from keras import layers\n",
    "\n",
    "mlp = Sequential()\n",
    "mlp.add(Flatten(input_shape=(48,48)))\n",
    "mlp.add(Dense(256,activation='relu'))\n",
    "mlp.add(Dense(512,activation='relu'))\n",
    "mlp.add(Dense(1024,activation='relu'))\n",
    "mlp.add(Dense(7,activation='softmax'))\n",
    "mlp.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "221/225 [============================>.] - ETA: 0s - loss: 1.7746 - accuracy: 0.2791\n",
      "Epoch 00001: val_loss improved from inf to 1.74384, saving model to ..\\models\\mlp_prototype.hdf5\n",
      "225/225 [==============================] - 2s 10ms/step - loss: 1.7733 - accuracy: 0.2795 - val_loss: 1.7438 - val_accuracy: 0.3034\n",
      "Epoch 2/10\n",
      "222/225 [============================>.] - ETA: 0s - loss: 1.6917 - accuracy: 0.3308\n",
      "Epoch 00002: val_loss improved from 1.74384 to 1.66037, saving model to ..\\models\\mlp_prototype.hdf5\n",
      "225/225 [==============================] - 2s 10ms/step - loss: 1.6915 - accuracy: 0.3309 - val_loss: 1.6604 - val_accuracy: 0.3466\n",
      "Epoch 3/10\n",
      "223/225 [============================>.] - ETA: 0s - loss: 1.6553 - accuracy: 0.3485\n",
      "Epoch 00003: val_loss improved from 1.66037 to 1.63687, saving model to ..\\models\\mlp_prototype.hdf5\n",
      "225/225 [==============================] - 2s 11ms/step - loss: 1.6552 - accuracy: 0.3485 - val_loss: 1.6369 - val_accuracy: 0.3589\n",
      "Epoch 4/10\n",
      "222/225 [============================>.] - ETA: 0s - loss: 1.6381 - accuracy: 0.3557\n",
      "Epoch 00004: val_loss did not improve from 1.63687\n",
      "225/225 [==============================] - 3s 12ms/step - loss: 1.6376 - accuracy: 0.3560 - val_loss: 1.6820 - val_accuracy: 0.3405\n",
      "Epoch 5/10\n",
      "222/225 [============================>.] - ETA: 0s - loss: 1.6240 - accuracy: 0.3608\n",
      "Epoch 00005: val_loss improved from 1.63687 to 1.62355, saving model to ..\\models\\mlp_prototype.hdf5\n",
      "225/225 [==============================] - 3s 12ms/step - loss: 1.6231 - accuracy: 0.3613 - val_loss: 1.6235 - val_accuracy: 0.3656\n",
      "Epoch 6/10\n",
      "225/225 [==============================] - ETA: 0s - loss: 1.6117 - accuracy: 0.3648\n",
      "Epoch 00006: val_loss improved from 1.62355 to 1.61189, saving model to ..\\models\\mlp_prototype.hdf5\n",
      "225/225 [==============================] - 2s 11ms/step - loss: 1.6117 - accuracy: 0.3648 - val_loss: 1.6119 - val_accuracy: 0.3711\n",
      "Epoch 7/10\n",
      "221/225 [============================>.] - ETA: 0s - loss: 1.5968 - accuracy: 0.3738\n",
      "Epoch 00007: val_loss improved from 1.61189 to 1.60893, saving model to ..\\models\\mlp_prototype.hdf5\n",
      "225/225 [==============================] - 2s 11ms/step - loss: 1.5965 - accuracy: 0.3737 - val_loss: 1.6089 - val_accuracy: 0.3734\n",
      "Epoch 8/10\n",
      "224/225 [============================>.] - ETA: 0s - loss: 1.5813 - accuracy: 0.3791\n",
      "Epoch 00008: val_loss improved from 1.60893 to 1.58815, saving model to ..\\models\\mlp_prototype.hdf5\n",
      "225/225 [==============================] - 2s 11ms/step - loss: 1.5815 - accuracy: 0.3789 - val_loss: 1.5882 - val_accuracy: 0.3748\n",
      "Epoch 9/10\n",
      "223/225 [============================>.] - ETA: 0s - loss: 1.5791 - accuracy: 0.3791\n",
      "Epoch 00009: val_loss did not improve from 1.58815\n",
      "225/225 [==============================] - 3s 13ms/step - loss: 1.5797 - accuracy: 0.3789 - val_loss: 1.6033 - val_accuracy: 0.3667\n",
      "Epoch 10/10\n",
      "223/225 [============================>.] - ETA: 0s - loss: 1.5754 - accuracy: 0.3808\n",
      "Epoch 00010: val_loss improved from 1.58815 to 1.58693, saving model to ..\\models\\mlp_prototype.hdf5\n",
      "225/225 [==============================] - 2s 11ms/step - loss: 1.5758 - accuracy: 0.3811 - val_loss: 1.5869 - val_accuracy: 0.3706\n"
     ]
    }
   ],
   "source": [
    "mlp_epoch = 10\n",
    "\n",
    "mlp_checkpointer = ModelCheckpoint(filepath='..\\models\\mlp_prototype.hdf5',verbose=1,save_best_only= True)\n",
    "\n",
    "mlp_hist = mlp.fit(tr_inputs, tr_targets , \n",
    "          validation_data=(t_inputs , t_targets),\n",
    "          epochs=mlp_epoch, batch_size=128, callbacks=[mlp_checkpointer], verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
